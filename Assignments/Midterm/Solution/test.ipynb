{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      " [{1: ['Iphone14', 'Iphone15']}, {2: ['Iphone12', 'Iphone13']}, {3: ['Iphone14']}, {4: ['Iphone11', 'Iphone10', 'Iphone14']}, {5: ['Iphone14', 'Iphone15', 'Iphone10']}, {6: ['Iphone10']}, {7: ['Iphone9', 'Iphone8', 'Iphone10']}, {8: ['Iphone9']}, {9: ['Iphone9', 'Iphone15', 'Iphone5']}, {10: ['Iphone8']}, {11: ['Iphone14', 'Iphone15', 'Iphone10', 'Iphone11']}, {12: ['Iphone7']}, {13: ['Iphone7', 'Iphone6', 'Iphone5']}, {14: ['Iphone6']}, {15: ['Iphone10', 'Iphone15', 'Iphone9']}, {16: ['Iphone5']}, {17: ['Iphone4', 'Iphone15', 'Iphone11']}, {18: ['Iphone4']}, {19: ['Iphone6', 'Iphone7', 'Iphone5']}, {20: ['Iphone3']}]\n",
      "1\n",
      "\n",
      "frequent_itemset {'Iphone14': 5, 'Iphone15': 6, 'Iphone12': 1, 'Iphone13': 1, 'Iphone11': 3, 'Iphone10': 6, 'Iphone9': 4, 'Iphone8': 2, 'Iphone5': 4, 'Iphone7': 3, 'Iphone6': 3, 'Iphone4': 2, 'Iphone3': 1}\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "frequent_itemset {('Iphone14', 'Iphone15'): 3, ('Iphone14', 'Iphone11'): 2, ('Iphone14', 'Iphone10'): 3, ('Iphone15', 'Iphone11'): 2, ('Iphone15', 'Iphone10'): 3, ('Iphone15', 'Iphone9'): 2, ('Iphone15', 'Iphone5'): 1, ('Iphone15', 'Iphone4'): 1, ('Iphone12', 'Iphone13'): 1, ('Iphone11', 'Iphone10'): 2, ('Iphone11', 'Iphone4'): 1, ('Iphone10', 'Iphone9'): 2, ('Iphone10', 'Iphone8'): 1, ('Iphone9', 'Iphone8'): 1, ('Iphone9', 'Iphone5'): 1, ('Iphone5', 'Iphone7'): 2, ('Iphone5', 'Iphone6'): 2, ('Iphone7', 'Iphone6'): 2}\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "frequent_itemset {('Iphone14', 'Iphone15', 'Iphone11'): 1, ('Iphone14', 'Iphone15', 'Iphone10'): 2, ('Iphone14', 'Iphone11', 'Iphone10'): 2, ('Iphone15', 'Iphone11', 'Iphone10'): 1, ('Iphone15', 'Iphone11', 'Iphone4'): 1, ('Iphone15', 'Iphone10', 'Iphone9'): 1, ('Iphone15', 'Iphone9', 'Iphone5'): 1, ('Iphone10', 'Iphone9', 'Iphone8'): 1, ('Iphone5', 'Iphone7', 'Iphone6'): 2}\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "frequent_itemset {('Iphone14', 'Iphone15', 'Iphone11', 'Iphone10'): 1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_txt(file_name):\n",
    "    content_file = []\n",
    "    # Open the file for reading\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split each line into two parts: the number and iPhone models\n",
    "            parts = line.strip().split(' ', 1)\n",
    "            \n",
    "            # Extract the number and iPhone models\n",
    "            number = int(parts[0])\n",
    "            models = parts[1].split(', ')\n",
    "            \n",
    "            # Create a dictionary for the current line and append it to the content list\n",
    "            content_file.append({number: models})\n",
    "    return content_file\n",
    "\n",
    "# def get_combinations(dictionary_data, combination_size):\n",
    "#     keys = list(dictionary_data.keys())\n",
    "\n",
    "#     # Check if combination_size is valid\n",
    "#     if combination_size <= 0 or combination_size > len(keys):\n",
    "#         return []\n",
    "\n",
    "#     # Initialize an empty list to store combinations\n",
    "#     combinations_list = []\n",
    "\n",
    "#     # Helper function to generate combinations recursively\n",
    "#     def generate_combinations(current_combination, remaining_keys, size):\n",
    "#         if size == 0:\n",
    "#             combinations_list.append(tuple(current_combination))\n",
    "#             return\n",
    "\n",
    "#         for i in range(len(remaining_keys)):\n",
    "#             new_combination = current_combination + [remaining_keys[i]]\n",
    "#             generate_combinations(new_combination, remaining_keys[i + 1:], size - 1)\n",
    "\n",
    "#     generate_combinations([], keys, combination_size)\n",
    "\n",
    "#     return combinations_list\n",
    "\n",
    "def get_combinations(dictionary_data, combination_size):\n",
    "    keys = list(dictionary_data.keys())\n",
    "\n",
    "    # Check if combination_size is valid\n",
    "    if combination_size <= 0 or combination_size > len(keys):\n",
    "        return []\n",
    "\n",
    "    # Initialize an empty list to store combinations\n",
    "    combinations_list = []\n",
    "\n",
    "    # Helper function to generate combinations recursively\n",
    "    def generate_combinations(current_combination, start_index, size):\n",
    "        if size == 0:\n",
    "            combinations_list.append(tuple(current_combination))\n",
    "            return\n",
    "\n",
    "        for i in range(start_index, len(keys)):\n",
    "            new_combination = current_combination + [keys[i]]\n",
    "            generate_combinations(new_combination, i + 1, size - 1)\n",
    "\n",
    "    generate_combinations([], 0, combination_size)\n",
    "\n",
    "    return combinations_list\n",
    "\n",
    "\n",
    "\n",
    "def brute_force(data):\n",
    "    i = 0\n",
    "    flag = True\n",
    "    frequent_itemset = []\n",
    "    while flag:\n",
    "        current_trans = 1\n",
    "        frequent_itemset.append({})\n",
    "        if i == 0:\n",
    "            for trans in data:\n",
    "                # Check if the current transaction number exists in the dictionary\n",
    "                if current_trans in trans:\n",
    "                    number = tuple(trans[current_trans])  # Convert the list to a tuple\n",
    "                    # Increment the count for the current number in the current table\n",
    "                    for item in number:\n",
    "                        if item in frequent_itemset[i]:\n",
    "                            frequent_itemset[i][item] += 1\n",
    "                        else:\n",
    "                            frequent_itemset[i][item] = 1\n",
    "\n",
    "                current_trans += 1\n",
    "        comb = get_combinations(frequent_itemset[0], i + 1)\n",
    "        \n",
    "\n",
    "        if i > 0:\n",
    "            \n",
    "            frequent_itemset.append({})\n",
    "            for each_comb in comb:\n",
    "                \n",
    "                current_trans = 1\n",
    "                for trans in data:\n",
    "                    previous_item_tracker = True\n",
    "                    \n",
    "                    transaction_numbers = trans.keys()  # Get the keys (transaction numbers) in the current trans\n",
    "                    if current_trans not in transaction_numbers:\n",
    "                        continue  # Skip this transaction if current_trans doesn't exist in the keys\n",
    "                    for item in each_comb:\n",
    "                        \n",
    "                        if (item in trans[current_trans]) and (previous_item_tracker):\n",
    "                            previous_item_tracker = True\n",
    "                        else:\n",
    "                            \n",
    "                            previous_item_tracker = False\n",
    "                           \n",
    "                            \n",
    "                            \n",
    "                    if previous_item_tracker:\n",
    "                        \n",
    "                        if each_comb in frequent_itemset[i]:\n",
    "                           \n",
    "                            \n",
    "                            frequent_itemset[i][each_comb] += 1\n",
    "                            \n",
    "                        else:\n",
    "                            frequent_itemset[i][each_comb] = 1\n",
    "                    \n",
    "                    current_trans += 1\n",
    "                        \n",
    "            \n",
    "        i += 1 \n",
    "        if len(frequent_itemset[i-1]) == 0:\n",
    "            break\n",
    "        \n",
    "        print(i)\n",
    "        print(\"\\nfrequent_itemset\", frequent_itemset[i-1])\n",
    "        print('\\n')\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "# Print the content list\n",
    "content = read_txt(\"transaction1.txt\")\n",
    "print(\"Data\\n\",content)\n",
    "brute_force(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGiven the following , genereate combinations in following ways and write a function:\\ninput: ('Iphone14', 'Iphone15')\\noutput: [[('Iphone14'), ('Iphone15')], [('Iphone15', ('Iphone14'))]\\n\\ninput: ('Iphone14', 'Iphone15', 'Iphone11')\\noutput: [[('Iphone14', 'Iphone15'), ('Iphone11')], [('Iphone14', 'Iphone11'), ('Iphone15')], [('Iphone15', 'Iphone11'), ('Iphone14')], [('Iphone14'), ('Iphone15', 'Iphone11')], [('Iphone15'), ('Iphone14', 'Iphone11')], [('Iphone11'), ('Iphone15', 'Iphone14')]] \\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given the following , genereate combinations in following ways and write a function:\n",
    "input: ('Iphone14', 'Iphone15')\n",
    "output: [[('Iphone14'), ('Iphone15')], [('Iphone15', ('Iphone14'))]\n",
    "\n",
    "input: ('Iphone14', 'Iphone15', 'Iphone11')\n",
    "output: [[('Iphone14', 'Iphone15'), ('Iphone11')], [('Iphone14', 'Iphone11'), ('Iphone15')], [('Iphone15', 'Iphone11'), ('Iphone14')], [('Iphone14'), ('Iphone15', 'Iphone11')], [('Iphone15'), ('Iphone14', 'Iphone11')], [('Iphone11'), ('Iphone15', 'Iphone14')]] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/suraj/miniconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/suraj/miniconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/suraj/miniconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/suraj/miniconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/suraj/miniconda3/lib/python3.11/site-packages (from pandas) (1.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/suraj/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mlxtend in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from mlxtend) (1.11.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from mlxtend) (1.26.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from mlxtend) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from mlxtend) (1.3.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from mlxtend) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from scikit-learn>=1.0.2->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "%pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori\n",
    "# Create a one-hot encoded dataframe\n",
    "import pandas as pd\n",
    "transactions_t = []\n",
    "for item in content:\n",
    "    for key, values in item.items():\n",
    "        transaction = {}\n",
    "        for value in values:\n",
    "            transaction[value] = 1\n",
    "        transactions_t.append(transaction)\n",
    "\n",
    "df = pd.DataFrame(transactions_t).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, support, confidence]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suraj/miniconda3/envs/datamining/lib/python3.11/site-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Using the apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\n",
    "\n",
    "# Generating association rules from the frequent itemsets\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             antecedents           consequents  antecedent support  \\\n",
      "0             (Iphone11)            (Iphone10)                0.15   \n",
      "1             (Iphone10)            (Iphone11)                0.30   \n",
      "2             (Iphone14)            (Iphone10)                0.25   \n",
      "3             (Iphone10)            (Iphone14)                0.30   \n",
      "4             (Iphone10)            (Iphone15)                0.30   \n",
      "5             (Iphone15)            (Iphone10)                0.30   \n",
      "6              (Iphone9)            (Iphone10)                0.20   \n",
      "7             (Iphone10)             (Iphone9)                0.30   \n",
      "8             (Iphone11)            (Iphone14)                0.15   \n",
      "9             (Iphone14)            (Iphone11)                0.25   \n",
      "10            (Iphone11)            (Iphone15)                0.15   \n",
      "11            (Iphone15)            (Iphone11)                0.30   \n",
      "12            (Iphone14)            (Iphone15)                0.25   \n",
      "13            (Iphone15)            (Iphone14)                0.30   \n",
      "14             (Iphone9)            (Iphone15)                0.20   \n",
      "15            (Iphone15)             (Iphone9)                0.30   \n",
      "16             (Iphone6)             (Iphone5)                0.15   \n",
      "17             (Iphone5)             (Iphone6)                0.20   \n",
      "18             (Iphone7)             (Iphone5)                0.15   \n",
      "19             (Iphone5)             (Iphone7)                0.20   \n",
      "20             (Iphone7)             (Iphone6)                0.15   \n",
      "21             (Iphone6)             (Iphone7)                0.15   \n",
      "22  (Iphone11, Iphone14)            (Iphone10)                0.10   \n",
      "23  (Iphone11, Iphone10)            (Iphone14)                0.10   \n",
      "24  (Iphone14, Iphone10)            (Iphone11)                0.15   \n",
      "25            (Iphone11)  (Iphone14, Iphone10)                0.15   \n",
      "26            (Iphone14)  (Iphone11, Iphone10)                0.25   \n",
      "27            (Iphone10)  (Iphone11, Iphone14)                0.30   \n",
      "28  (Iphone14, Iphone10)            (Iphone15)                0.15   \n",
      "29  (Iphone14, Iphone15)            (Iphone10)                0.15   \n",
      "30  (Iphone10, Iphone15)            (Iphone14)                0.15   \n",
      "31            (Iphone14)  (Iphone10, Iphone15)                0.25   \n",
      "32            (Iphone10)  (Iphone14, Iphone15)                0.30   \n",
      "33            (Iphone15)  (Iphone14, Iphone10)                0.30   \n",
      "34    (Iphone7, Iphone6)             (Iphone5)                0.10   \n",
      "35    (Iphone7, Iphone5)             (Iphone6)                0.10   \n",
      "36    (Iphone6, Iphone5)             (Iphone7)                0.10   \n",
      "37             (Iphone7)    (Iphone6, Iphone5)                0.15   \n",
      "38             (Iphone6)    (Iphone7, Iphone5)                0.15   \n",
      "39             (Iphone5)    (Iphone7, Iphone6)                0.20   \n",
      "\n",
      "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "0                 0.30     0.10    0.666667  2.222222    0.0550    2.100000   \n",
      "1                 0.15     0.10    0.333333  2.222222    0.0550    1.275000   \n",
      "2                 0.30     0.15    0.600000  2.000000    0.0750    1.750000   \n",
      "3                 0.25     0.15    0.500000  2.000000    0.0750    1.500000   \n",
      "4                 0.30     0.15    0.500000  1.666667    0.0600    1.400000   \n",
      "5                 0.30     0.15    0.500000  1.666667    0.0600    1.400000   \n",
      "6                 0.30     0.10    0.500000  1.666667    0.0400    1.400000   \n",
      "7                 0.20     0.10    0.333333  1.666667    0.0400    1.200000   \n",
      "8                 0.25     0.10    0.666667  2.666667    0.0625    2.250000   \n",
      "9                 0.15     0.10    0.400000  2.666667    0.0625    1.416667   \n",
      "10                0.30     0.10    0.666667  2.222222    0.0550    2.100000   \n",
      "11                0.15     0.10    0.333333  2.222222    0.0550    1.275000   \n",
      "12                0.30     0.15    0.600000  2.000000    0.0750    1.750000   \n",
      "13                0.25     0.15    0.500000  2.000000    0.0750    1.500000   \n",
      "14                0.30     0.10    0.500000  1.666667    0.0400    1.400000   \n",
      "15                0.20     0.10    0.333333  1.666667    0.0400    1.200000   \n",
      "16                0.20     0.10    0.666667  3.333333    0.0700    2.400000   \n",
      "17                0.15     0.10    0.500000  3.333333    0.0700    1.700000   \n",
      "18                0.20     0.10    0.666667  3.333333    0.0700    2.400000   \n",
      "19                0.15     0.10    0.500000  3.333333    0.0700    1.700000   \n",
      "20                0.15     0.10    0.666667  4.444444    0.0775    2.550000   \n",
      "21                0.15     0.10    0.666667  4.444444    0.0775    2.550000   \n",
      "22                0.30     0.10    1.000000  3.333333    0.0700         inf   \n",
      "23                0.25     0.10    1.000000  4.000000    0.0750         inf   \n",
      "24                0.15     0.10    0.666667  4.444444    0.0775    2.550000   \n",
      "25                0.15     0.10    0.666667  4.444444    0.0775    2.550000   \n",
      "26                0.10     0.10    0.400000  4.000000    0.0750    1.500000   \n",
      "27                0.10     0.10    0.333333  3.333333    0.0700    1.350000   \n",
      "28                0.30     0.10    0.666667  2.222222    0.0550    2.100000   \n",
      "29                0.30     0.10    0.666667  2.222222    0.0550    2.100000   \n",
      "30                0.25     0.10    0.666667  2.666667    0.0625    2.250000   \n",
      "31                0.15     0.10    0.400000  2.666667    0.0625    1.416667   \n",
      "32                0.15     0.10    0.333333  2.222222    0.0550    1.275000   \n",
      "33                0.15     0.10    0.333333  2.222222    0.0550    1.275000   \n",
      "34                0.20     0.10    1.000000  5.000000    0.0800         inf   \n",
      "35                0.15     0.10    1.000000  6.666667    0.0850         inf   \n",
      "36                0.15     0.10    1.000000  6.666667    0.0850         inf   \n",
      "37                0.10     0.10    0.666667  6.666667    0.0850    2.700000   \n",
      "38                0.10     0.10    0.666667  6.666667    0.0850    2.700000   \n",
      "39                0.10     0.10    0.500000  5.000000    0.0800    1.800000   \n",
      "\n",
      "    zhangs_metric  \n",
      "0        0.647059  \n",
      "1        0.785714  \n",
      "2        0.666667  \n",
      "3        0.714286  \n",
      "4        0.571429  \n",
      "5        0.571429  \n",
      "6        0.500000  \n",
      "7        0.571429  \n",
      "8        0.735294  \n",
      "9        0.833333  \n",
      "10       0.647059  \n",
      "11       0.785714  \n",
      "12       0.666667  \n",
      "13       0.714286  \n",
      "14       0.500000  \n",
      "15       0.571429  \n",
      "16       0.823529  \n",
      "17       0.875000  \n",
      "18       0.823529  \n",
      "19       0.875000  \n",
      "20       0.911765  \n",
      "21       0.911765  \n",
      "22       0.777778  \n",
      "23       0.833333  \n",
      "24       0.911765  \n",
      "25       0.911765  \n",
      "26       1.000000  \n",
      "27       1.000000  \n",
      "28       0.647059  \n",
      "29       0.647059  \n",
      "30       0.735294  \n",
      "31       0.833333  \n",
      "32       0.785714  \n",
      "33       0.785714  \n",
      "34       0.888889  \n",
      "35       0.944444  \n",
      "36       0.944444  \n",
      "37       1.000000  \n",
      "38       1.000000  \n",
      "39       1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the data\n",
    "with open(\"transaction1.txt\", 'r') as f:\n",
    "    transactions = [line.strip().split() for line in f.readlines()]\n",
    "\n",
    "# Cleaning the data: Removing transaction IDs and trailing commas from item names\n",
    "cleaned_transactions = [ [item.replace(',', '') for item in transaction[1:]] for transaction in transactions]\n",
    "\n",
    "# Convert the transactions into a one-hot encoded DataFrame\n",
    "items = sorted(list(set(item for transaction in cleaned_transactions for item in transaction)))\n",
    "oht = pd.DataFrame([[item in transaction for item in items] for transaction in cleaned_transactions], columns=items)\n",
    "\n",
    "# Apply the Apriori algorithm\n",
    "frequent_itemsets = apriori(oht, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             antecedents           consequents  antecedent support  \\\n",
      "0             (Iphone11)            (Iphone10)                0.15   \n",
      "1             (Iphone10)            (Iphone11)                0.30   \n",
      "2             (Iphone14)            (Iphone10)                0.25   \n",
      "3             (Iphone10)            (Iphone14)                0.30   \n",
      "4             (Iphone10)            (Iphone15)                0.30   \n",
      "5             (Iphone15)            (Iphone10)                0.30   \n",
      "6              (Iphone9)            (Iphone10)                0.20   \n",
      "7             (Iphone10)             (Iphone9)                0.30   \n",
      "8             (Iphone11)            (Iphone14)                0.15   \n",
      "9             (Iphone14)            (Iphone11)                0.25   \n",
      "10            (Iphone11)            (Iphone15)                0.15   \n",
      "11            (Iphone15)            (Iphone11)                0.30   \n",
      "12            (Iphone14)            (Iphone15)                0.25   \n",
      "13            (Iphone15)            (Iphone14)                0.30   \n",
      "14             (Iphone9)            (Iphone15)                0.20   \n",
      "15            (Iphone15)             (Iphone9)                0.30   \n",
      "16             (Iphone6)             (Iphone5)                0.15   \n",
      "17             (Iphone5)             (Iphone6)                0.20   \n",
      "18             (Iphone7)             (Iphone5)                0.15   \n",
      "19             (Iphone5)             (Iphone7)                0.20   \n",
      "20             (Iphone7)             (Iphone6)                0.15   \n",
      "21             (Iphone6)             (Iphone7)                0.15   \n",
      "22  (Iphone11, Iphone14)            (Iphone10)                0.10   \n",
      "23  (Iphone11, Iphone10)            (Iphone14)                0.10   \n",
      "24  (Iphone14, Iphone10)            (Iphone11)                0.15   \n",
      "25            (Iphone11)  (Iphone14, Iphone10)                0.15   \n",
      "26            (Iphone14)  (Iphone11, Iphone10)                0.25   \n",
      "27            (Iphone10)  (Iphone11, Iphone14)                0.30   \n",
      "28  (Iphone14, Iphone10)            (Iphone15)                0.15   \n",
      "29  (Iphone14, Iphone15)            (Iphone10)                0.15   \n",
      "30  (Iphone10, Iphone15)            (Iphone14)                0.15   \n",
      "31            (Iphone14)  (Iphone10, Iphone15)                0.25   \n",
      "32            (Iphone10)  (Iphone14, Iphone15)                0.30   \n",
      "33            (Iphone15)  (Iphone14, Iphone10)                0.30   \n",
      "34    (Iphone7, Iphone6)             (Iphone5)                0.10   \n",
      "35    (Iphone7, Iphone5)             (Iphone6)                0.10   \n",
      "36    (Iphone6, Iphone5)             (Iphone7)                0.10   \n",
      "37             (Iphone7)    (Iphone6, Iphone5)                0.15   \n",
      "38             (Iphone6)    (Iphone7, Iphone5)                0.15   \n",
      "39             (Iphone5)    (Iphone7, Iphone6)                0.20   \n",
      "\n",
      "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "0                 0.30     0.10    0.666667  2.222222    0.0550    2.100000   \n",
      "1                 0.15     0.10    0.333333  2.222222    0.0550    1.275000   \n",
      "2                 0.30     0.15    0.600000  2.000000    0.0750    1.750000   \n",
      "3                 0.25     0.15    0.500000  2.000000    0.0750    1.500000   \n",
      "4                 0.30     0.15    0.500000  1.666667    0.0600    1.400000   \n",
      "5                 0.30     0.15    0.500000  1.666667    0.0600    1.400000   \n",
      "6                 0.30     0.10    0.500000  1.666667    0.0400    1.400000   \n",
      "7                 0.20     0.10    0.333333  1.666667    0.0400    1.200000   \n",
      "8                 0.25     0.10    0.666667  2.666667    0.0625    2.250000   \n",
      "9                 0.15     0.10    0.400000  2.666667    0.0625    1.416667   \n",
      "10                0.30     0.10    0.666667  2.222222    0.0550    2.100000   \n",
      "11                0.15     0.10    0.333333  2.222222    0.0550    1.275000   \n",
      "12                0.30     0.15    0.600000  2.000000    0.0750    1.750000   \n",
      "13                0.25     0.15    0.500000  2.000000    0.0750    1.500000   \n",
      "14                0.30     0.10    0.500000  1.666667    0.0400    1.400000   \n",
      "15                0.20     0.10    0.333333  1.666667    0.0400    1.200000   \n",
      "16                0.20     0.10    0.666667  3.333333    0.0700    2.400000   \n",
      "17                0.15     0.10    0.500000  3.333333    0.0700    1.700000   \n",
      "18                0.20     0.10    0.666667  3.333333    0.0700    2.400000   \n",
      "19                0.15     0.10    0.500000  3.333333    0.0700    1.700000   \n",
      "20                0.15     0.10    0.666667  4.444444    0.0775    2.550000   \n",
      "21                0.15     0.10    0.666667  4.444444    0.0775    2.550000   \n",
      "22                0.30     0.10    1.000000  3.333333    0.0700         inf   \n",
      "23                0.25     0.10    1.000000  4.000000    0.0750         inf   \n",
      "24                0.15     0.10    0.666667  4.444444    0.0775    2.550000   \n",
      "25                0.15     0.10    0.666667  4.444444    0.0775    2.550000   \n",
      "26                0.10     0.10    0.400000  4.000000    0.0750    1.500000   \n",
      "27                0.10     0.10    0.333333  3.333333    0.0700    1.350000   \n",
      "28                0.30     0.10    0.666667  2.222222    0.0550    2.100000   \n",
      "29                0.30     0.10    0.666667  2.222222    0.0550    2.100000   \n",
      "30                0.25     0.10    0.666667  2.666667    0.0625    2.250000   \n",
      "31                0.15     0.10    0.400000  2.666667    0.0625    1.416667   \n",
      "32                0.15     0.10    0.333333  2.222222    0.0550    1.275000   \n",
      "33                0.15     0.10    0.333333  2.222222    0.0550    1.275000   \n",
      "34                0.20     0.10    1.000000  5.000000    0.0800         inf   \n",
      "35                0.15     0.10    1.000000  6.666667    0.0850         inf   \n",
      "36                0.15     0.10    1.000000  6.666667    0.0850         inf   \n",
      "37                0.10     0.10    0.666667  6.666667    0.0850    2.700000   \n",
      "38                0.10     0.10    0.666667  6.666667    0.0850    2.700000   \n",
      "39                0.10     0.10    0.500000  5.000000    0.0800    1.800000   \n",
      "\n",
      "    zhangs_metric  \n",
      "0        0.647059  \n",
      "1        0.785714  \n",
      "2        0.666667  \n",
      "3        0.714286  \n",
      "4        0.571429  \n",
      "5        0.571429  \n",
      "6        0.500000  \n",
      "7        0.571429  \n",
      "8        0.735294  \n",
      "9        0.833333  \n",
      "10       0.647059  \n",
      "11       0.785714  \n",
      "12       0.666667  \n",
      "13       0.714286  \n",
      "14       0.500000  \n",
      "15       0.571429  \n",
      "16       0.823529  \n",
      "17       0.875000  \n",
      "18       0.823529  \n",
      "19       0.875000  \n",
      "20       0.911765  \n",
      "21       0.911765  \n",
      "22       0.777778  \n",
      "23       0.833333  \n",
      "24       0.911765  \n",
      "25       0.911765  \n",
      "26       1.000000  \n",
      "27       1.000000  \n",
      "28       0.647059  \n",
      "29       0.647059  \n",
      "30       0.735294  \n",
      "31       0.833333  \n",
      "32       0.785714  \n",
      "33       0.785714  \n",
      "34       0.888889  \n",
      "35       0.944444  \n",
      "36       0.944444  \n",
      "37       1.000000  \n",
      "38       1.000000  \n",
      "39       1.000000  \n"
     ]
    }
   ],
   "source": [
    "def read_txt(file_name):\n",
    "    content_file = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' ', 1)\n",
    "            number = int(parts[0])\n",
    "            models = parts[1].split(', ')\n",
    "            content_file.append({number: models})\n",
    "    return content_file\n",
    "\n",
    "def get_combinations(dictionary_data, combination_size):\n",
    "    keys = list(dictionary_data.keys())\n",
    "    if combination_size <= 0 or combination_size > len(keys):\n",
    "        return []\n",
    "    combinations_list = []\n",
    "    def generate_combinations(current_combination, start_index, size):\n",
    "        if size == 0:\n",
    "            combinations_list.append(tuple(current_combination))\n",
    "            return\n",
    "        for i in range(start_index, len(keys)):\n",
    "            new_combination = current_combination + [keys[i]]\n",
    "            generate_combinations(new_combination, i + 1, size - 1)\n",
    "    generate_combinations([], 0, combination_size)\n",
    "    return combinations_list\n",
    "\n",
    "def corrected_brute_force_v2(data):\n",
    "    i = 0\n",
    "    flag = True\n",
    "    tables = []\n",
    "    while flag:\n",
    "        current_trans = 1\n",
    "        tables.append({})\n",
    "        comb = get_combinations(tables[0], i + 1)\n",
    "        if i == 0:\n",
    "            for trans in data:\n",
    "                if current_trans in trans:\n",
    "                    number = tuple(trans[current_trans])\n",
    "                    for item in number:\n",
    "                        if item in tables[i]:\n",
    "                            tables[i][item] += 1\n",
    "                        else:\n",
    "                            tables[i][item] = 1\n",
    "                current_trans += 1\n",
    "        else:\n",
    "            for each_comb in comb:\n",
    "                current_trans = 1\n",
    "                for trans in data:\n",
    "                    previous_item_tracker = True\n",
    "                    transaction_numbers = trans.keys()\n",
    "                    if current_trans not in transaction_numbers:\n",
    "                        continue\n",
    "                    for item in each_comb:\n",
    "                        if (item in trans[current_trans]) and (previous_item_tracker):\n",
    "                            previous_item_tracker = True\n",
    "                        else:\n",
    "                            previous_item_tracker = False\n",
    "                    if previous_item_tracker:\n",
    "                        if each_comb in tables[i]:\n",
    "                            tables[i][each_comb] += 1\n",
    "                        else:\n",
    "                            tables[i][each_comb] = 1\n",
    "                    current_trans += 1\n",
    "        i += 1 \n",
    "        if i == 10:\n",
    "            flag = False\n",
    "    return tables\n",
    "\n",
    "def calculate_support_adjusted(itemset, num_transactions, single_item_itemsets, two_item_itemsets):\n",
    "    if len(itemset) == 1:\n",
    "        return single_item_itemsets.get(itemset[0], 1e-9) / num_transactions\n",
    "    elif len(itemset) == 2:\n",
    "        return two_item_itemsets.get(itemset, 1e-9) / num_transactions\n",
    "    return 1e-9\n",
    "\n",
    "def generate_all_rules(data, tables, min_support, min_confidence):\n",
    "    num_transactions = len(data)\n",
    "    rules = []\n",
    "\n",
    "    for table in tables:\n",
    "        for itemset, count in table.items():\n",
    "            if isinstance(itemset, tuple) and len(itemset) > 1:\n",
    "                itemset_support = count / num_transactions\n",
    "                for i in range(1, len(itemset)):\n",
    "                    from itertools import combinations\n",
    "                    for subset in combinations(itemset, i):\n",
    "                        antecedent = tuple(subset)\n",
    "                        consequent = tuple(sorted(set(itemset) - set(antecedent)))\n",
    "                        \n",
    "                        confidence = itemset_support / calculate_support_adjusted(antecedent, num_transactions, tables[0], tables[1])\n",
    "                        if confidence >= min_confidence and itemset_support >= min_support:\n",
    "                            rules.append((antecedent, consequent, itemset_support, confidence))\n",
    "    return rules\n",
    "\n",
    "# Execution\n",
    "content = read_txt(\"transaction1.txt\")\n",
    "tables = corrected_brute_force_v2(content)\n",
    "min_support_value = 1\n",
    "min_confidence_value = 0.1\n",
    "all_rules = generate_all_rules(content, tables, min_support_value, min_confidence_value)\n",
    "\n",
    "# Print all the association rules\n",
    "for rule in all_rules:\n",
    "    antecedent, consequent, support, confidence = rule\n",
    "    print(f\"{antecedent} => {consequent} (Support: {support:.2f}, Confidence: {confidence:.2f})\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the data\n",
    "with open(\"transaction1.txt\", 'r') as f:\n",
    "    transactions = [line.strip().split() for line in f.readlines()]\n",
    "\n",
    "# Cleaning the data: Removing transaction IDs and trailing commas from item names\n",
    "cleaned_transactions = [ [item.replace(',', '') for item in transaction[1:]] for transaction in transactions]\n",
    "\n",
    "# Convert the transactions into a one-hot encoded DataFrame\n",
    "items = sorted(list(set(item for transaction in cleaned_transactions for item in transaction)))\n",
    "oht = pd.DataFrame([[item in transaction for item in items] for transaction in cleaned_transactions], columns=items)\n",
    "\n",
    "# Apply the Apriori algorithm\n",
    "frequent_itemsets = apriori(oht, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining",
   "language": "python",
   "name": "datamining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
